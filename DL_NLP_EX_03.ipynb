{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl0YjZi6DzlL"
      },
      "source": [
        "## Ecrire un programme qui calcule la similarité entre deux documents avec deux approches différentes :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZTzmh7TEB_U"
      },
      "source": [
        "### Uniquement en utilisant la comparaison lexicale des mots des deux documents et en utilisant WodNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YywwDOyq4yqd",
        "outputId": "3ebf086a-5879-4538-c46a-3f6629b9c6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5Xp3kxCEIol",
        "outputId": "462346b2-8577-4349-bb27-b41776ec32de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_set1 inter word_set2{'mat', '.'}\n",
            "word_set1 inter word_set2{'mat', '.'}\n",
            "Similarité lexicale: 0.4\n",
            "Similarité WordNet: 1.0\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Télécharger les ressources nécessaires de NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenisation des mots\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Suppression des mots vides (stop words)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    # Lemmatisation des mots\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return tokens\n",
        "\n",
        "def lexical_similarity(doc1, doc2):\n",
        "    tokens1 = preprocess_text(doc1)\n",
        "    tokens2 = preprocess_text(doc2)\n",
        "    \n",
        "    # Construction des ensembles de mots uniques pour chaque document\n",
        "    word_set1 = set(tokens1)\n",
        "    word_set2 = set(tokens2)\n",
        "    \n",
        "    # Calcul de la similarité lexicale en utilisant l'intersection des ensembles de mots\n",
        "    print('word_set1 inter word_set2'+str(word_set1.intersection(word_set2)))\n",
        "    print('word_set1 inter word_set2'+str(word_set2.intersection(word_set1)))\n",
        "    similarity = len(word_set1.intersection(word_set2)) / float(len(word_set1.union(word_set2)))\n",
        "    return similarity\n",
        "\n",
        "def wordnet_similarity(doc1, doc2):\n",
        "    tokens1 = preprocess_text(doc1)\n",
        "    tokens2 = preprocess_text(doc2)\n",
        "    \n",
        "    # Calcul de la similarité en utilisant WordNet\n",
        "    synsets1 = set()\n",
        "    synsets2 = set()\n",
        "    \n",
        "    # Obtenir les synsets pour chaque mot dans le premier document\n",
        "    for token in tokens1:\n",
        "        synsets = wordnet.synsets(token)\n",
        "        synsets1.update(synsets)\n",
        "    \n",
        "    # Obtenir les synsets pour chaque mot dans le deuxième document\n",
        "    for token in tokens2:\n",
        "        synsets = wordnet.synsets(token)\n",
        "        synsets2.update(synsets)\n",
        "    \n",
        "    # Calcul de la similarité en utilisant le coefficient de similarité de path\n",
        "    max_similarity = 0\n",
        "    for synset1 in synsets1:\n",
        "        for synset2 in synsets2:\n",
        "            similarity = synset1.path_similarity(synset2)\n",
        "            if similarity is not None and similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "    \n",
        "    return max_similarity\n",
        "\n",
        "# Exemple d'utilisation\n",
        "document1 = \"The cat sits on the mat.\"\n",
        "document2 = \"The dog is on the mat.\"\n",
        "\n",
        "lex_similarity = lexical_similarity(document1, document2)\n",
        "wrndt_similarity = wordnet_similarity(document1, document2)\n",
        "\n",
        "print(\"Similarité lexicale:\", lex_similarity)\n",
        "print(\"Similarité WordNet:\", wrndt_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz9KtLRPESI3",
        "outputId": "7e6e1f04-4c56-449f-e343-5603263f353c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_set1 inter word_set2{'.'}\n",
            "word_set1 inter word_set2{'.'}\n",
            "Similarité lexicale: 0.2\n",
            "Similarité WordNet: 0.3333333333333333\n"
          ]
        }
      ],
      "source": [
        "document3 = \"everything everywhere all at once .\"\n",
        "document4 = \"The dog is on the mat.\"\n",
        "\n",
        "lex_similarity = lexical_similarity(document3, document4)\n",
        "wrdnt_similarity = wordnet_similarity(document3, document4)\n",
        "\n",
        "print(\"Similarité lexicale:\", lex_similarity)\n",
        "print(\"Similarité WordNet:\", wrdnt_similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z8sOlOTtr2G"
      },
      "source": [
        "## Utiliser un classificateur basé sur votre implémentation de la régression logistique pour implémenter un système d'analyse de sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E6vaEuyot1x0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class LogisticRegression:\n",
        "    \n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.scaler = StandardScaler()  # StandardScaler for feature scaling\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        num_samples, num_features = X.shape\n",
        "        self.weights = np.zeros(num_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Scale the features\n",
        "        X = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Gradient descent optimization\n",
        "        for _ in range(self.num_iterations):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_pred = self.sigmoid(linear_model)\n",
        "\n",
        "            dw = (1 / num_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / num_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            # Update weights and bias\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Scale the features\n",
        "        X = self.scaler.transform(X)\n",
        "        \n",
        "        # Predict the probability of the positive class\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_pred = self.sigmoid(linear_model)\n",
        "        \n",
        "        # Convert probability to class labels\n",
        "        y_pred_class = np.where(y_pred > 0.5, 1, 0)\n",
        "        return y_pred_class\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QhCEBJLlwj6_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d0492876-1a09-48f0-fec0-ce09adb7cadf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          clean_text  category\n",
              "0  when modi promised “minimum government maximum...      -1.0\n",
              "1  what did just say vote for modi  welcome bjp t...       1.0\n",
              "2  asking his supporters prefix chowkidar their n...       1.0\n",
              "3  answer who among these the most powerful world...       1.0\n",
              "4  with upcoming election india saga going import...       1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d6b0faf-09b2-4c1e-be8e-7c0d03ba8f95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>asking his supporters prefix chowkidar their n...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>answer who among these the most powerful world...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>with upcoming election india saga going import...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d6b0faf-09b2-4c1e-be8e-7c0d03ba8f95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d6b0faf-09b2-4c1e-be8e-7c0d03ba8f95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d6b0faf-09b2-4c1e-be8e-7c0d03ba8f95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "tweets = pd.read_csv('/content/data.csv')\n",
        "tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XFPdgZsBxEqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fabeae-cbea-468b-9ccf-62f6d1123796"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "clean_text    2\n",
              "category      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tweets.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dSjYBJqpxc_f"
      },
      "outputs": [],
      "source": [
        "# Text preprocessing\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def expand_contractions(sentence):\n",
        "    contractions = {\n",
        "        \"ain't\": \"am not\",\n",
        "        \"aren't\": \"are not\",\n",
        "        \"can't\": \"cannot\",\n",
        "        \"can't've\": \"cannot have\",\n",
        "        \"'cause\": \"because\",\n",
        "        \"could've\": \"could have\",\n",
        "        \"couldn't\": \"could not\",\n",
        "        \"couldn't've\": \"could not have\",\n",
        "        \"didn't\": \"did not\",\n",
        "        \"doesn't\": \"does not\",\n",
        "        \"don't\": \"do not\",\n",
        "        \"hadn't\": \"had not\",\n",
        "        \"hadn't've\": \"had not have\",\n",
        "        \"hasn't\": \"has not\",\n",
        "        \"haven't\": \"have not\",\n",
        "        \"he'd\": \"he would\",\n",
        "        \"he'd've\": \"he would have\",\n",
        "        \"he'll\": \"he will\",\n",
        "        \"he'll've\": \"he will have\",\n",
        "        \"he's\": \"he is\",\n",
        "        \"how'd\": \"how did\",\n",
        "        \"how'd'y\": \"how do you\",\n",
        "        \"how'll\": \"how will\",\n",
        "        \"how's\": \"how is\",\n",
        "        \"I'd\": \"I would\",\n",
        "        \"I'd've\": \"I would have\",\n",
        "        \"I'll\": \"I will\",\n",
        "        \"I'll've\": \"I will have\",\n",
        "        \"I'm\": \"I am\",\n",
        "        \"I've\": \"I have\",\n",
        "        \"isn't\": \"is not\",\n",
        "        \"it'd\": \"it would\",\n",
        "        \"it'd've\": \"it would have\",\n",
        "        \"it'll\": \"it will\",\n",
        "        \"it'll've\": \"it will have\",\n",
        "        \"it's\": \"it is\",\n",
        "        \"let's\": \"let us\",\n",
        "        \"ma'am\": \"madam\",\n",
        "        \"mayn't\": \"may not\",\n",
        "        \"might've\": \"might have\",\n",
        "        \"mightn't\": \"might not\",\n",
        "        \"mightn't've\": \"might not have\",\n",
        "        \"must've\": \"must have\",\n",
        "        \"mustn't\": \"must not\",\n",
        "        \"mustn't've\": \"must not have\",\n",
        "        \"needn't\": \"need not\",\n",
        "        \"needn't've\": \"need not have\",\n",
        "        \"o'clock\": \"of the clock\",\n",
        "        \"oughtn't\": \"ought not\",\n",
        "        \"oughtn't've\": \"ought not have\",\n",
        "        \"shan't\": \"shall not\",\n",
        "        \"sha'n't\": \"shall not\",\n",
        "        \"shan't've\": \"shall not have\",\n",
        "        \"she'd\": \"she would\",\n",
        "        \"she'd've\": \"she would have\",\n",
        "        \"she'll\": \"she will\",\n",
        "        \"she'll've\": \"she will have\",\n",
        "        \"she's\": \"she is\",\n",
        "        \"should've\": \"should have\",\n",
        "        \"shouldn't\": \"should not\",\n",
        "        \"shouldn't've\": \"should not have\",\n",
        "        \"so've\": \"so have\",\n",
        "        \"so's\": \"so is\",\n",
        "        \"that'd\": \"that would\",\n",
        "        \"that'd've\": \"that would have\",\n",
        "        \"that's\": \"that is\",\n",
        "        \"there'd\": \"there would\",\n",
        "        \"there'd've\": \"there would have\",\n",
        "        \"there's\": \"there is\",\n",
        "        \"they'd\": \"they would\",\n",
        "        \"they'd've\": \"they would have\",\n",
        "        \"they'll\": \"they will\",\n",
        "        \"they'll've\": \"they will have\",\n",
        "        \"they're\": \"they are\",\n",
        "        \"they've\": \"they have\",\n",
        "        \"to've\": \"to have\",\n",
        "        \"wasn't\": \"was not\",\n",
        "        \"we'd\": \"we would\",\n",
        "        \"we'd've\": \"we would have\",\n",
        "        \"we'll\": \"we will\",\n",
        "        \"we'll've\": \"we will have\",\n",
        "        \"we're\": \"we are\",\n",
        "        \"we've\": \"we have\",\n",
        "        \"weren't\": \"were not\",\n",
        "        \"what'll\": \"what will\",\n",
        "        \"what'll've\": \"what will have\",\n",
        "        \"what're\": \"what are\",\n",
        "        \"what's\": \"what is\",\n",
        "        \"what've\": \"what have\",\n",
        "        \"when's\": \"when is\",\n",
        "        \"when've\": \"when have\",\n",
        "        \"where'd\": \"where did\",\n",
        "        \"where's\": \"where is\",\n",
        "        \"where've\": \"where have\",\n",
        "        \"who'll\": \"who will\",\n",
        "        \"who'll've\": \"who will have\",\n",
        "        \"who's\": \"who is\",\n",
        "        \"who've\": \"who have\",\n",
        "        \"why's\": \"why is\",\n",
        "        \"why've\": \"why have\",\n",
        "        \"will've\": \"will have\",\n",
        "        \"won't\": \"will not\",\n",
        "        \"won't've\": \"will not have\",\n",
        "        \"would've\": \"would have\",\n",
        "        \"wouldn't\": \"would not\",\n",
        "        \"wouldn't've\": \"would not have\",\n",
        "        \"y'all\": \"you all\",\n",
        "        \"y'all'd\": \"you all would\",\n",
        "        \"y'all'd've\": \"you all would have\",\n",
        "        \"y'all're\": \"you all are\",\n",
        "        \"y'all've\": \"you all have\",\n",
        "        \"you'd\": \"you would\",\n",
        "        \"you'd've\": \"you would have\",\n",
        "        \"you'll\": \"you will\",\n",
        "        \"you'll've\": \"you will have\",\n",
        "        \"you're\": \"you are\",\n",
        "        \"you've\": \"you have\"\n",
        "    }\n",
        "\n",
        "    # Create a regular expression pattern to match the contractions\n",
        "    pattern = re.compile(r'\\b(' + '|'.join(contractions.keys()) + r')\\b')\n",
        "\n",
        "    # Function to replace the matched contractions with their expanded forms\n",
        "    def replace(match):\n",
        "        return contractions[match.group(0)]\n",
        "\n",
        "    # Use the sub() function with the replace function to expand contractions\n",
        "    expanded_sentence = re.sub(pattern, replace, sentence)\n",
        "\n",
        "    return expanded_sentence\n",
        "\n",
        "def lemmatize_sentence(sentence):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(sentence)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token, 'v') for token in tokens]\n",
        "    lemmatized_sentence = ' '.join(lemmatized_tokens)\n",
        "    return lemmatized_sentence\n",
        "\n",
        "def delete_stopwords(sentence):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    filtered_sentence = ' '.join(filtered_tokens)\n",
        "    return filtered_sentence\n",
        "\n",
        "def text_cleaning(x):\n",
        "    # To replace consecutive whitespace and newline characters with a single space character in the string\n",
        "    q = re.sub('\\s+\\n+', ' ', x)\n",
        "    \n",
        "    # To lowercase\n",
        "    q = q.lower()\n",
        "    \n",
        "    # expand contractions\n",
        "    q = expand_contractions(q)\n",
        "    \n",
        "    # To replace any non-alphanumeric character in the string \n",
        "    q = re.sub('[^a-zA-Z0-9]', ' ', q)\n",
        "    \n",
        "    # Lemmatization\n",
        "    q = lemmatize_sentence(q)\n",
        "    \n",
        "    return delete_stopwords(q)\n",
        "\n",
        "# Cleaning\n",
        "def clean(data):\n",
        "    data.dropna(axis=0, inplace=True)\n",
        "    data.drop_duplicates(inplace=True)\n",
        "    \n",
        "    data['clean_text'] = data['clean_text'].apply(text_cleaning)\n",
        "    data.dropna(axis=0, inplace=True)\n",
        "    data.drop_duplicates(inplace=True)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "etM_nGRlzOoY"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hR542IVzzTc-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "92f4a1e9-04a6-40fb-b130-5b38a4f96f81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          clean_text  category\n",
              "0  modi promise minimum government maximum govern...      -1.0\n",
              "1  say vote modi welcome bjp tell rahul main camp...       1.0\n",
              "2  ask supporters prefix chowkidar name modi grea...       1.0\n",
              "3  answer among powerful world leader today trump...       1.0\n",
              "4  upcoming election india saga go important pair...       1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76c3abd5-7286-4703-b0dc-46abe7fbbf81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>modi promise minimum government maximum govern...</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>say vote modi welcome bjp tell rahul main camp...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ask supporters prefix chowkidar name modi grea...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>answer among powerful world leader today trump...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>upcoming election india saga go important pair...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76c3abd5-7286-4703-b0dc-46abe7fbbf81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76c3abd5-7286-4703-b0dc-46abe7fbbf81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76c3abd5-7286-4703-b0dc-46abe7fbbf81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "copy_data = deepcopy(tweets)\n",
        "cleaned_data = clean(copy_data)\n",
        "cleaned_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T_eZyfr0ze-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d00daeb2-31a7-454f-87a9-1e0ea2c9a3dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "cleaned_data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RbENvRTgz3Gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb28790-0a8b-4a27-c428-645b982f65a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105352, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "cleaned_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7S6qbijCz9bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7919c589-eb01-4787-cf81-737eae06f877"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "clean_text    0\n",
              "category      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "cleaned_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-vYXUt-O0Erh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63529615-2328-46b2-8352-c418e395ec35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['modi',\n",
              " 'promise',\n",
              " 'minimum',\n",
              " 'government',\n",
              " 'maximum',\n",
              " 'governance',\n",
              " 'expect',\n",
              " 'begin',\n",
              " 'difficult',\n",
              " 'job',\n",
              " 'reform',\n",
              " 'state',\n",
              " 'take',\n",
              " 'years',\n",
              " 'get',\n",
              " 'justice',\n",
              " 'state',\n",
              " 'business',\n",
              " 'exit',\n",
              " 'psus',\n",
              " 'temples']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tweets_list = list(cleaned_data['clean_text'].apply(lambda x: x.split()))\n",
        "tweets_list[0] # list of lists, where each tweet is a list of tokens, finally we have a list of tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_O78CkRN0jRF"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "# train model\n",
        "w2v_model = Word2Vec(tweets_list, vector_size = 100, window = 5, min_count=5, sg=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cBBQ2vz302OJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b683918-95c2-4db3-a1f5-0a07d13fdc72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14501"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(w2v_model.wv.index_to_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EeztGBa11Dk2"
      },
      "outputs": [],
      "source": [
        "def document_vector(doc):\n",
        "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
        "    \n",
        "    # doc1 contains those words of the document which are included in the vocab\n",
        "    doc1 = [word for word in doc.split() if word in w2v_model.wv.index_to_key]\n",
        "    \n",
        "    wv1 = []  # this will contain the WE of all the vocab words from the doc\n",
        "    for word in doc1:\n",
        "        wv1.append(w2v_model.wv.get_vector(word))\n",
        "    wv1_ = np.array(wv1)\n",
        "    wv1_mean = wv1_.mean(axis=0)\n",
        "    return wv1_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NAjU538I1M_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a3f45e6-b8b7-45ef-f243-7634d522b6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-e5215b04b234>:11: RuntimeWarning: Mean of empty slice.\n",
            "  wv1_mean = wv1_.mean(axis=0)\n"
          ]
        }
      ],
      "source": [
        "tweets_temp = cleaned_data['clean_text'].apply(document_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QpIaflmn1T_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7ff9345-1682-4699-976c-944b7309d3ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105352,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tweets_temp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4IbPJqTX1Wa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad598e59-8e2b-4be3-f72a-22a4d4f47f44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105352, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Combining all the document vectors into a singl numpy array (tweets_vec)\n",
        "embedding_size = 100\n",
        "tweets_vec = np.ones((len(tweets_temp), embedding_size))*np.nan\n",
        "for i in range(tweets_vec.shape[0]):\n",
        "    tweets_vec[i,:] = tweets_temp.iloc[i]\n",
        "\n",
        "tweets_vec.shape # this itself is your final FEATURE MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xZSNb-jZ1fJy"
      },
      "outputs": [],
      "source": [
        "# Create a new DF to store these new documnent features\n",
        "def labels(x):\n",
        "  return 1 if x == 1.0 else 0\n",
        "df = pd.DataFrame(tweets_vec)\n",
        "df['y'] = cleaned_data['category'].apply(labels)\n",
        "df.dropna(axis=0, inplace=True)\n",
        "df['y'] = df['y'].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NL9Fa38W1w8u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "594f7ca3-e66c-48fb-e5ee-02e644efd96d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0         1         2         3         4         5         6  \\\n",
              "105347 -0.109156  0.218626 -0.094113 -0.050349 -0.656277 -0.883146  0.066947   \n",
              "105348  0.151471 -0.030912 -0.077932  0.459758 -0.705213 -0.586198  0.548455   \n",
              "105349  0.409441  0.209597 -0.926300 -0.082187 -0.632302  0.039838  0.159867   \n",
              "105350 -0.132154  0.090676  0.136290  0.083055 -0.358178 -0.684826 -0.001598   \n",
              "105351 -0.288728  0.161791  0.058654 -0.232482 -0.571144 -0.761337  0.177801   \n",
              "\n",
              "               7         8         9  ...        91        92        93  \\\n",
              "105347  0.244081 -0.131661 -0.479267  ...  0.244661  0.277166  0.359339   \n",
              "105348  0.348201 -0.624291 -0.122178  ... -0.214388 -0.174044 -0.075074   \n",
              "105349  0.279283 -1.058787 -0.229327  ...  0.003318  0.087381  0.052750   \n",
              "105350  0.740921 -0.419746 -0.045070  ...  0.074847 -0.200783 -0.151354   \n",
              "105351  1.065071 -0.198533 -0.055657  ...  0.036758 -0.235612 -0.460114   \n",
              "\n",
              "              94        95        96        97        98        99  y  \n",
              "105347  0.164642  0.141335  0.085223 -0.301285  0.174231 -0.013893  1  \n",
              "105348  0.358728  0.479100  0.429342 -1.042958  0.271623  0.218519  0  \n",
              "105349  0.938481  0.629492 -0.203367  0.083050  0.286326 -0.449901  1  \n",
              "105350  0.388028  0.435986  0.141373 -0.323119 -0.062025  0.327149  1  \n",
              "105351  0.236416  0.351797 -0.007563 -0.469839  0.376313  0.127802  1  \n",
              "\n",
              "[5 rows x 101 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a233733-5a81-46c2-8343-fd3191742c8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>105347</th>\n",
              "      <td>-0.109156</td>\n",
              "      <td>0.218626</td>\n",
              "      <td>-0.094113</td>\n",
              "      <td>-0.050349</td>\n",
              "      <td>-0.656277</td>\n",
              "      <td>-0.883146</td>\n",
              "      <td>0.066947</td>\n",
              "      <td>0.244081</td>\n",
              "      <td>-0.131661</td>\n",
              "      <td>-0.479267</td>\n",
              "      <td>...</td>\n",
              "      <td>0.244661</td>\n",
              "      <td>0.277166</td>\n",
              "      <td>0.359339</td>\n",
              "      <td>0.164642</td>\n",
              "      <td>0.141335</td>\n",
              "      <td>0.085223</td>\n",
              "      <td>-0.301285</td>\n",
              "      <td>0.174231</td>\n",
              "      <td>-0.013893</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105348</th>\n",
              "      <td>0.151471</td>\n",
              "      <td>-0.030912</td>\n",
              "      <td>-0.077932</td>\n",
              "      <td>0.459758</td>\n",
              "      <td>-0.705213</td>\n",
              "      <td>-0.586198</td>\n",
              "      <td>0.548455</td>\n",
              "      <td>0.348201</td>\n",
              "      <td>-0.624291</td>\n",
              "      <td>-0.122178</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.214388</td>\n",
              "      <td>-0.174044</td>\n",
              "      <td>-0.075074</td>\n",
              "      <td>0.358728</td>\n",
              "      <td>0.479100</td>\n",
              "      <td>0.429342</td>\n",
              "      <td>-1.042958</td>\n",
              "      <td>0.271623</td>\n",
              "      <td>0.218519</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105349</th>\n",
              "      <td>0.409441</td>\n",
              "      <td>0.209597</td>\n",
              "      <td>-0.926300</td>\n",
              "      <td>-0.082187</td>\n",
              "      <td>-0.632302</td>\n",
              "      <td>0.039838</td>\n",
              "      <td>0.159867</td>\n",
              "      <td>0.279283</td>\n",
              "      <td>-1.058787</td>\n",
              "      <td>-0.229327</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003318</td>\n",
              "      <td>0.087381</td>\n",
              "      <td>0.052750</td>\n",
              "      <td>0.938481</td>\n",
              "      <td>0.629492</td>\n",
              "      <td>-0.203367</td>\n",
              "      <td>0.083050</td>\n",
              "      <td>0.286326</td>\n",
              "      <td>-0.449901</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105350</th>\n",
              "      <td>-0.132154</td>\n",
              "      <td>0.090676</td>\n",
              "      <td>0.136290</td>\n",
              "      <td>0.083055</td>\n",
              "      <td>-0.358178</td>\n",
              "      <td>-0.684826</td>\n",
              "      <td>-0.001598</td>\n",
              "      <td>0.740921</td>\n",
              "      <td>-0.419746</td>\n",
              "      <td>-0.045070</td>\n",
              "      <td>...</td>\n",
              "      <td>0.074847</td>\n",
              "      <td>-0.200783</td>\n",
              "      <td>-0.151354</td>\n",
              "      <td>0.388028</td>\n",
              "      <td>0.435986</td>\n",
              "      <td>0.141373</td>\n",
              "      <td>-0.323119</td>\n",
              "      <td>-0.062025</td>\n",
              "      <td>0.327149</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105351</th>\n",
              "      <td>-0.288728</td>\n",
              "      <td>0.161791</td>\n",
              "      <td>0.058654</td>\n",
              "      <td>-0.232482</td>\n",
              "      <td>-0.571144</td>\n",
              "      <td>-0.761337</td>\n",
              "      <td>0.177801</td>\n",
              "      <td>1.065071</td>\n",
              "      <td>-0.198533</td>\n",
              "      <td>-0.055657</td>\n",
              "      <td>...</td>\n",
              "      <td>0.036758</td>\n",
              "      <td>-0.235612</td>\n",
              "      <td>-0.460114</td>\n",
              "      <td>0.236416</td>\n",
              "      <td>0.351797</td>\n",
              "      <td>-0.007563</td>\n",
              "      <td>-0.469839</td>\n",
              "      <td>0.376313</td>\n",
              "      <td>0.127802</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a233733-5a81-46c2-8343-fd3191742c8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a233733-5a81-46c2-8343-fd3191742c8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a233733-5a81-46c2-8343-fd3191742c8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8igMSkjQ1x4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebefcde-0185-49f2-9643-82416d182c15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102988, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X = df.drop('y',axis=1)\n",
        "y = df['y']\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Oz6BEwp91-Nj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6eb8692-4fb9-4280-8034-26674c2eb06a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82390"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)\n",
        "\n",
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "no7PdlBd2HGs"
      },
      "outputs": [],
      "source": [
        "LR_model = LogisticRegression()\n",
        "LR_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XOLlViR16U8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f13770-6dd5-47ce-9578-b8a7885d2e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "Int64Index: 102988 entries, 0 to 105351\n",
            "Series name: y\n",
            "Non-Null Count   Dtype\n",
            "--------------   -----\n",
            "102988 non-null  int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 1.6 MB\n"
          ]
        }
      ],
      "source": [
        "df['y'].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TBbypOid2PtR"
      },
      "outputs": [],
      "source": [
        "y_pred=LR_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vnnbcVci2VCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f42309f-26d4-486a-b7a3-2f9af3e13bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      6846\n",
            "           1       0.67      1.00      0.80     13752\n",
            "\n",
            "    accuracy                           0.67     20598\n",
            "   macro avg       0.33      0.50      0.40     20598\n",
            "weighted avg       0.45      0.67      0.53     20598\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}